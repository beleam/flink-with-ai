{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d0b20df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyflink.dataset import ExecutionEnvironment\n",
    "from pyflink.table import TableConfig, DataTypes, BatchTableEnvironment, StreamTableEnvironment\n",
    "from pyflink.table.descriptors import Schema, OldCsv, FileSystem\n",
    "from pyflink.table.udf import udf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c04d342",
   "metadata": {},
   "source": [
    "# Source and Sink FileSystem StreamTable Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0a077707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyflink.table.table_result.TableResult at 0x7f9d13b16080>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyflink.datastream import StreamExecutionEnvironment, TimeCharacteristic\n",
    "from pyflink.table import StreamTableEnvironment, EnvironmentSettings\n",
    "\n",
    "s_env = StreamExecutionEnvironment.get_execution_environment()\n",
    "s_env.set_stream_time_characteristic(TimeCharacteristic.EventTime)\n",
    "s_env.set_parallelism(1)\n",
    "\n",
    "# use blink table planner\n",
    "st_env = StreamTableEnvironment \\\n",
    "    .create(s_env, environment_settings=EnvironmentSettings\n",
    "            .new_instance()\n",
    "            .in_streaming_mode()\n",
    "            .use_blink_planner().build())\n",
    "\n",
    "\n",
    "# FileSystem source\n",
    "source_ddl = \"\"\"CREATE TABLE MySourceTable (word varchar) WITH (\n",
    "        'connector.type' = 'filesystem',\n",
    "        'format.type' = 'csv',\n",
    "        'connector.path' = '/opt/flink/notebooks/data/word_count_input')\n",
    "\"\"\"\n",
    "\n",
    "# FileSystem sink\n",
    "sink_ddl = \"\"\"CREATE TABLE MySinkTable (\n",
    "    word varchar,\n",
    "    cnt bigint) WITH (\n",
    "        'connector.type' = 'filesystem',\n",
    "        'format.type' = 'csv',\n",
    "        'connector.path' = '/opt/flink/notebooks/data/word_count_output1')\n",
    "\"\"\"\n",
    "\n",
    "# Mysql sink\n",
    "sinkdb_ddl = \"\"\"CREATE TABLE MySinkDbTable (\n",
    "    word varchar,\n",
    "    cnt bigint) WITH (\n",
    "        'connector.type' = 'jdbc',\n",
    "        'connector.url' = 'jdbc:mysql://mysql:3306/test',\n",
    "        'connector.table' = 'word_count',\n",
    "        'connector.driver' = 'com.mysql.jdbc.Driver',\n",
    "        'connector.write.flush.interval' = '10',\n",
    "        'connector.username' = 'root',\n",
    "        'connector.password' = 'my-secret-pw')\n",
    "\"\"\"\n",
    "\n",
    "sinkdbsms_ddl = \"\"\"CREATE TABLE MySinkDbSmsTable (\n",
    "    smstext varchar,\n",
    "    smstype varchar) WITH (\n",
    "        'connector.type' = 'jdbc',\n",
    "        'connector.url' = 'jdbc:mysql://mysql:3306/test',\n",
    "        'connector.table' = 'sms',\n",
    "        'connector.driver' = 'com.mysql.jdbc.Driver',\n",
    "        'connector.write.flush.interval' = '10',\n",
    "        'connector.username' = 'root',\n",
    "        'connector.password' = 'my-secret-pw')\n",
    "\"\"\"\n",
    "\n",
    "# Kafka source\n",
    "source_kafka_ddl = \"\"\"CREATE TABLE MySourceKafkaTable (word varchar) WITH (\n",
    "    'connector.type' = 'kafka',\n",
    "    'connector.version' = 'universal',\n",
    "    'connector.topic' = 'test',\n",
    "    'connector.startup-mode' = 'latest-offset',\n",
    "    'connector.properties.bootstrap.servers' = 'kafka:9092',\n",
    "    'connector.properties.group.id' = 'test',\n",
    "    'format.type' = 'csv'\n",
    "        )\n",
    "\"\"\"\n",
    "\n",
    "st_env.execute_sql(source_kafka_ddl)\n",
    "st_env.execute_sql(source_ddl)\n",
    "st_env.execute_sql(sink_ddl)\n",
    "st_env.execute_sql(sinkdb_ddl)\n",
    "st_env.execute_sql(sinkdbsms_ddl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb715c0",
   "metadata": {},
   "source": [
    "# Define UDF function using PyFlink"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f404a689",
   "metadata": {},
   "source": [
    "Let's use the mlflow model to have abstraction over multiple frameworks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "edca3338",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyflink.table.expressions import call \n",
    "from pyflink.table.udf import ScalarFunction\n",
    "\n",
    "class SpamClassifier(ScalarFunction):\n",
    "    def __init__(self, model_id):\n",
    "        import mlflow.sklearn\n",
    "        self.model = mlflow.sklearn.load_model(f\"/mlflow/mlruns/2/{model_id}/artifacts/model\")\n",
    "\n",
    "    def eval(self, s):\n",
    "        res=self.model.predict([s])\n",
    "        return res[0]\n",
    "        #return s\n",
    "\n",
    "spam_classifier = udf(SpamClassifier(\"64a89b0a6b7346498316bfae4c298535\"), input_types=[DataTypes.STRING()], result_type=DataTypes.STRING())\n",
    "\n",
    "st_env.register_function(\"SPAM_CLASSIFIER\",spam_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85a2579",
   "metadata": {},
   "source": [
    "# Define pipeline using SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a29b9fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyflink.table.table_result.TableResult at 0x7f05fb4c36a0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st_env.execute_sql(\"INSERT INTO MySinkTable SELECT word as smstext, SPAM_CLASSIFIER(word) as smstype FROM MySourceKafkaTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "096f97fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyflink.table.table_result.TableResult at 0x7f9dae2e9470>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st_env.execute_sql(\"INSERT INTO MySinkDbSmsTable SELECT word as smstext, SPAM_CLASSIFIER(word) as smstype FROM MySourceKafkaTable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4857f2",
   "metadata": {},
   "source": [
    "# Define pipeline using PyFlink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8c5ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_env.from_path('MySourceKafkaTable') \\\n",
    "    .select('smstext, SPAM_CLASSIFIER(word)') \\\n",
    "    .insert_into('MySinkDbTable')\n",
    "\n",
    "st_env.execute(\"5-word_count-mysql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6e9f55",
   "metadata": {},
   "source": [
    "# Drop Sources and Sink definitions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfa9395",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_env.execute_sql(\"DROP TABLE MySourceTable\")\n",
    "st_env.execute_sql(\"DROP TABLE MySinkTable\")\n",
    "st_env.execute_sql(\"DROP TABLE MySinkDbTable\")\n",
    "st_env.execute_sql(\"DROP TABLE MySourceKafkaTable\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
